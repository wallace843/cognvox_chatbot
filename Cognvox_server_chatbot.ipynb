{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wallace843/cognvox_chatbot/blob/main/Cognvox_server_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMbG-FxHidCm",
        "outputId": "ca189a31-dda9-41bb-e9cd-c8b28a5d063f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: llama-cpp-python==0.2.88 in /usr/local/lib/python3.10/dist-packages (0.2.88)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.88) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.88) (1.26.4)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.88) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.88) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Collecting argparse (from anvil-uplink)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (1.16.0)\n",
            "Requirement already satisfied: ws4py-sslupdate in /usr/local/lib/python3.10/dist-packages (from anvil-uplink) (0.5.1b0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.88) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n",
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install pandas anvil-uplink spacy llama-cpp-python==0.2.88 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf_pp6WQ3JHU"
      },
      "outputs": [],
      "source": [
        "TEMPO_DE_ESPERA = 10\n",
        "RESPOSTA_LONGA = 30\n",
        "PERC_KW_RATING = 0.6\n",
        "\n",
        "NOME_CRIANCA = \"JOÃO\"\n",
        "ID_SESSAO = \"SESSÃO 1\"\n",
        "ID_DESENHO = \"DESENHO 1\"\n",
        "\n",
        "KEYWORD_FILEPATH_URL = \"https://github.com/wallace843/cognvox_chatbot/raw/refs/heads/main/artefatos/03_Palavras_Chaves_REF.xlsx\"\n",
        "BIG_QUESTION_FILEPATH_URL = \"https://github.com/wallace843/cognvox_chatbot/raw/refs/heads/main/artefatos/04_Base_Perguntas_FRAME_7_DEPRECATED.xlsx\"\n",
        "SMALL_QUESTION_FILEPATH_URL = \"https://github.com/wallace843/cognvox_chatbot/raw/refs/heads/main/artefatos/04_Base_Perguntas_FRAME_8_9_10_11.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIty06ChW8Ap",
        "outputId": "89a20874-e970-4ae7-891b-056dc61edc5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('big_questions.xlsx', <http.client.HTTPMessage at 0x79303d36faf0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import anvil.server\n",
        "import anvil\n",
        "import random\n",
        "from llama_cpp import Llama\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "\n",
        "anvil.server.connect(\"server_XBWQZNK44PBUQ7LP75NU23UW-NSYADLNRH65TEPDA\")\n",
        "\n",
        "KEYWORD_FILEPATH = \"key_words.xlsx\"\n",
        "BIG_QUESTION_FILEPATH = \"big_questions.xlsx\"\n",
        "SMALL_QUESTION_FILEPATH = \"small_questions.xlsx\"\n",
        "\n",
        "urllib.request.urlretrieve(KEYWORD_FILEPATH_URL, filename=KEYWORD_FILEPATH)\n",
        "urllib.request.urlretrieve(SMALL_QUESTION_FILEPATH_URL, filename=SMALL_QUESTION_FILEPATH)\n",
        "urllib.request.urlretrieve(BIG_QUESTION_FILEPATH_URL, filename=BIG_QUESTION_FILEPATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmSc2YqW_GZl"
      },
      "outputs": [],
      "source": [
        "class FrameEstateComp:\n",
        "  def __init__(self, options_list_massages):\n",
        "    self.options_list_massages = options_list_massages\n",
        "\n",
        "  def randomOutput(self):\n",
        "    print(self.options_list_massages)\n",
        "    len_options = len(self.options_list_massages)\n",
        "    if len_options == 0:\n",
        "      return None\n",
        "    int_random = random.randint(0, len_options - 1)\n",
        "    return llm.correct_grammar(self.options_list_massages.pop(int_random))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F33paIb0RAps"
      },
      "source": [
        "Frames centrais de lógica mais simples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYGhCyZ-A2aZ"
      },
      "outputs": [],
      "source": [
        "class FrameSaudacao(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"Olá {NOME_CRIANCA}, estou feliz de estar com você aqui. Vamos começar a {ID_SESSAO}.\",\n",
        "      f\"Olá {NOME_CRIANCA}, que bom que você veio. Vamos gravar a {ID_SESSAO}.\",\n",
        "      f\"Olá {NOME_CRIANCA}, bem vindo! Nesta {ID_SESSAO} você vai ver um {ID_DESENHO}.\",\n",
        "      f\"Oi {NOME_CRIANCA}, bem vindo, vamos começar a {ID_SESSAO}, com um {ID_DESENHO}.\",\n",
        "      f\"Oi {NOME_CRIANCA}, vamos começar a {ID_SESSAO},seja bem vindo. Na tela aparecem quatro {ID_DESENHO}.\",\n",
        "      f\"Oba {NOME_CRIANCA}, que bom ter você aqui! Vamos começar a {ID_SESSAO}!\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    return FrameDirecionamento()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameDirecionamento(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"Nesta tela tem um {ID_DESENHO} que você vai olhar para contar uma história. Mas fique tranquilo, neste {ID_DESENHO} não tem, certo nem errado, é você que vai contar como quiser.\",\n",
        "      f\"Nesta imagem na tela tem um {ID_DESENHO}, você vai contar o que acontece, não tem certo nem errado, vai ser uma história criada por você.\",\n",
        "      f\"Você está vendo na tela um {ID_DESENHO}. Esse {ID_DESENHO} não tem certo, nem errado, é você quem vai contar como quiser a história. Também não tem resposta bonita e nem feia. É a sua resposta e por isso tem a sua importância!\",\n",
        "      f\"Você vai contar sua própria história sobre esse {ID_DESENHO}, sem ter certo e nem errado, combinado? Fique à vontade.\",\n",
        "      f\"Para esse {ID_DESENHO}, não tem certo nem errado, é você que vai contar uma história como quiser, conta pra mim.\",\n",
        "      f\"Na tela está aparecendo um {ID_DESENHO}. Pode me contar o que acontece na história? Pode contar como quiser, não tem certo nem errado, é você que vai criar uma história! Também não se preocupe com o tempo. Leve o tempo que você precisar para dar a sua resposta.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    return FrameDirecionamento1()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameDirecionamento1(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"Vamos lá, pode contar {NOME_CRIANCA} sua historinha para mim?\",\n",
        "      f\"Vamos começar, {NOME_CRIANCA}?\",\n",
        "      f\"Podemos começar, {NOME_CRIANCA}?\",\n",
        "      f\"Está pronto para começar, {NOME_CRIANCA}?\",\n",
        "      f\"Está pronto para iniciar, {NOME_CRIANCA}?\",\n",
        "      f\"{NOME_CRIANCA}, podemos iniciar?\",\n",
        "      f\"{NOME_CRIANCA}, vamos iniciar?\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    return FrameDirecionamento2()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameDirecionamento2(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"{NOME_CRIANCA} Continuo aqui. Pode me falar o que você vê na imagem?\",\n",
        "      f\"Vamos começar, {NOME_CRIANCA}! Estou aqui para quando você quiser começar. O que você vê nos quadrinhos?\",\n",
        "      f\"Continuo aguardando! Conte-me o que você está vendo na historinha.\",\n",
        "      f\"Podemos começar assim que você quiser, me conte sua historinha {NOME_CRIANCA}.\",\n",
        "      f\"{NOME_CRIANCA}, podemos iniciar: me conte qualquer historinha sobre essa imagem.\",\n",
        "      f\"{NOME_CRIANCA}, vamos iniciar. Estou aguardando você contar uma historinha sobre essa imagem.\",\n",
        "      f\"{NOME_CRIANCA}, me fale o que você vê na imagem.\",\n",
        "      f\"Podemos começar assim que você quiser, me conte sua historinha {NOME_CRIANCA}.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    if self.nlp.cat_input_phrase(input) in [\"CURT\"]:\n",
        "      inicial_kw = self.nlp.get_keywords(input)\n",
        "      return FrameDesenvolvimentoComplexo(inicial_kw, [input])\n",
        "    elif self.nlp.cat_input_phrase(input) in [\"LONG\"]:\n",
        "      lst_input = input.split('.')\n",
        "      inicial_kw = self.nlp.get_keywords(lst_input[0])\n",
        "      return FrameDesenvolvimentoComplexo1(inicial_kw, lst_input)\n",
        "    else:\n",
        "      return FrameDirecionamento3()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "    self.nlp = NLP()\n",
        "\n",
        "class FrameDirecionamento3(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"{NOME_CRIANCA} Continuo aqui, pode me falar o que você vê na imagem?\",\n",
        "      f\"Vamos começar, {NOME_CRIANCA}, estou aqui para quando você quiser começar. O que você vê nos quadrinhos?\",\n",
        "      f\"Podemos começar assim que você quiser, me conte a historinha {NOME_CRIANCA}?\",\n",
        "      f\"{NOME_CRIANCA}, podemos iniciar: me conte qualquer historinha sobre essa imagem.\",\n",
        "      f\"{NOME_CRIANCA}, vamos iniciar. Estou aguardando você contar uma historinha sobre essa imagem.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    if self.nlp.cat_input_phrase(input) in [\"CURT\"]:\n",
        "      inicial_kw = self.nlp.get_keywords(input)\n",
        "      return FrameDesenvolvimentoComplexo(inicial_kw, [input])\n",
        "    elif self.nlp.cat_input_phrase(input) in [\"LONG\"]:\n",
        "      lst_input = input.split('.')\n",
        "      inicial_kw = self.nlp.get_keywords(lst_input[0])\n",
        "      return FrameDesenvolvimentoComplexo1(inicial_kw, lst_input)\n",
        "    else:\n",
        "      return FrameDirecionamento4()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "    self.nlp = NLP()\n",
        "\n",
        "class FrameDirecionamento4(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"{NOME_CRIANCA} Estou esperando por sua historinha. Fale-me o que você vê na imagem.\",\n",
        "      f\"Continuo aguardando! Conte-me o que você está vendo na historinha.\",\n",
        "      f\"Podemos começar assim que você quiser, me conte sua historinha {NOME_CRIANCA}.\",\n",
        "      f\"{NOME_CRIANCA}, podemos iniciar: me conte qualquer historinha sobre essa imagem.\",\n",
        "      f\"{NOME_CRIANCA}, vamos iniciar! Estou aguardando você contar uma historinha sobre essa imagem.\",\n",
        "      f\"{NOME_CRIANCA}, podemos iniciar: me conte qualquer historinha sobre essa imagem.\",\n",
        "      f\"{NOME_CRIANCA}, vamos iniciar. Estou aguardando você contar uma historinha sobre essa imagem.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    if self.nlp.cat_input_phrase(input) in [\"CURT\"]:\n",
        "      inicial_kw = self.nlp.get_keywords(input)\n",
        "      return FrameDesenvolvimentoComplexo(inicial_kw, [input])\n",
        "    elif self.nlp.cat_input_phrase(input) in [\"LONG\"]:\n",
        "      lst_input = input.split('.')\n",
        "      inicial_kw = self.nlp.get_keywords(lst_input[0])\n",
        "      return FrameDesenvolvimentoComplexo1(inicial_kw, lst_input)\n",
        "    else:\n",
        "      return FrameEncerramento1()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "    self.nlp = NLP()\n",
        "\n",
        "class FrameEncerramento1(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"{NOME_CRIANCA}, só isso ou quer me contar algo mais antes de finalizarmos?\",\n",
        "      f\"{NOME_CRIANCA} O que você tem para me falar antes de encerrarmos?\",\n",
        "      f\"Sua última chance de poder me dizer mais alguma coisa {NOME_CRIANCA} antes de encerramos.\",\n",
        "      f\"{NOME_CRIANCA}, conte-mais algo antes de finalizarmos, se você desejar.\",\n",
        "      f\"{NOME_CRIANCA}, qual outra coisa a mais para dizer antes de encerrarmos?\",\n",
        "      f\"{NOME_CRIANCA}, sua chance para me dizer uma última coisa antes de encerramos.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    return FrameEncerramento2()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameEncerramento2(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      \"Vamos combinar assim, encerramos por hoje esta sessão e, em outro dia, iniciaremos outra sessão e continuamos a conversa. Vou adorar!\",\n",
        "      \"Combinamos que seria uma sessão por dia, vamos encerrar e outro dia continuamos. Foi muito bom hoje!\",\n",
        "      \"Teremos que continuar outro dia, porque combinamos que seria uma sessão por dia, mas vou adorar ouvir você novamente.\",\n",
        "      \"Outro dia voltamos em outra sessão e conversamos mais. Uma sessão por dia está excelente.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    return FrameEncerramento()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameEncerramento(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      \"Pronto, muito bem! Vamos encerrar.\",\n",
        "      \"Que bom! Gostei de conversar com você.\",\n",
        "      \"Você foi muito bem. Até a próxima!\",\n",
        "      \"Excelente! Aprendi muito com você, vamos encerrar.\",\n",
        "      \"Ótimo, foi muito bom ouvir sua história. Valeu!\",\n",
        "      \"Que bom! Gostei muito de ouvir sua história.\",\n",
        "      \"Muito bem. Vamos encerrar.\",\n",
        "      \"Foi muito bom conversar com você. Estou encerrando por aqui.\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    return None\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameDesenvolvimento2(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      \"Certo, e o que mais?\",\n",
        "      \"O que mais podemos dizer dos outros quadrinhos na sua história?\",\n",
        "      \"Entendi. E o que mais?\",\n",
        "      \"Você pode me contar também dos outros quadrinhos?\",\n",
        "      \"Vamos continuar a história, passando para outros quadrinhos?\",\n",
        "      \"Que interessante! Agora conte também um pouco mais o que acontece nos outros quadrinhos.\",\n",
        "      \"E o que mais acontece em sua história?\",\n",
        "      \"Que interessante! Conte mais o que aconteceu?\",\n",
        "      \"E o que mais?\",\n",
        "      \"E aí? Conte mais.\",\n",
        "      \"Então, o que mais aconteceu?\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    if self.nlp.cat_input_phrase(input) in [\"POS\", \"NEG_C_EL\", \"LONG\", \"CURT\"] and len(all_keywords) < self.MAX_KW:\n",
        "      inicial_kw = self.nlp.get_keywords(input)\n",
        "      return FrameDesenvolvimentoComplexo(inicial_kw, dff_questions_small, input)\n",
        "    else:\n",
        "      return FrameCompreencao1()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "    self.nlp = NLP()\n",
        "\n",
        "class FrameCompreencao1(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"Maravilha! Pode repetir e contar de novo de uma vez só para encerrar?\",\n",
        "      f\"Ótimo! Gostei, poderia repetir a história toda, apenas para finalizar?\",\n",
        "      f\"Há algo mais que você queira contar sobre esse {ID_DESENHO}, {NOME_CRIANCA}?\",\n",
        "      f\"Mais alguma coisa a dizer sobre esse {ID_DESENHO}?\",\n",
        "      f\"Pode me dizer mais alguma coisas a respeito desse {ID_DESENHO}?\",\n",
        "      f\"{NOME_CRIANCA}, gostei muito de sua história. Pode contar de novo para eu gravar melhor?\",\n",
        "      f\"Excelente história, {NOME_CRIANCA}! Pode repetir toda a historinha de uma vez para encerrar a sessão?\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    if self.nlp.cat_input_phrase(input) in [\"POS\"]:\n",
        "      inicial_kw = self.nlp.get_keywords(input)\n",
        "      return FrameCompreencao2()\n",
        "    else:\n",
        "      return FrameEncerramento1()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)\n",
        "    self.nlp = NLP()\n",
        "\n",
        "class FrameCompreencao2(FrameEstateComp):\n",
        "  options_list_massages = [\n",
        "      f\"Maravilha! Conte para mim de novo de uma só vez então.\",\n",
        "      f\"Ótimo! Gostei! Você pode repetir agora a história toda apenas para finalizarmos.\",\n",
        "      f\"{NOME_CRIANCA}, gostei muito de sua história! Conte-me de novo para eu gravar melhor.\",\n",
        "      f\"Excelente história {NOME_CRIANCA}! Repita sua historinha toda de uma vez para encerrarmos a sessão.\",\n",
        "      f\"O que mais pode me dizer a respeito dessa historinha que você contou?\"\n",
        "  ]\n",
        "\n",
        "  def next_frame(self, input):\n",
        "      return FrameEncerramento1()\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(self.options_list_massages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhBOxdfBYzo4"
      },
      "source": [
        "Frame Desenvolvimento Complexo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9tzsUImY6ei"
      },
      "outputs": [],
      "source": [
        "class FrameDesenvolvimentoComplexo(FrameEstateComp):\n",
        "  MAX_KW = 5 * PERC_KW_RATING\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    global all_keywords\n",
        "    print(all_keywords)\n",
        "    if self.nlp.cat_input_phrase(input) in [\"POS\", \"NEG_C_EL\", \"LONG\", \"CURT\"] and len(all_keywords) < self.MAX_KW:\n",
        "      for question in self.options_list_massages:\n",
        "        for kw in self.recent_keywords:\n",
        "          question = question.replace(kw['word_used'], kw['word_id'])\n",
        "      self.questions_selected = self.questions_selected[self.questions_selected.apply(lambda row: row['PERGUNTA_FRASE_TEMPLATE'] in self.options_list_massages, axis=1)]\n",
        "      global df_questions_small\n",
        "      df_questions_small = pd.concat([self.questions_selected, self.questions_deselected])\n",
        "      print('len',len(df_questions_small))\n",
        "\n",
        "      self.queue_input_child.append(input)\n",
        "      temp_input = self.queue_input_child.pop(0)\n",
        "\n",
        "      self.inicial_kw = self.nlp.get_keywords(temp_input)\n",
        "      self.input_child = temp_input\n",
        "      print('len',len(df_questions_small))\n",
        "      self.options_list_massages = []\n",
        "      print('len',len(df_questions_small))\n",
        "      self.recent_keywords = self.inicial_kw['s'] + self.inicial_kw['v'] + self.inicial_kw['o']\n",
        "      print('len',len(df_questions_small))\n",
        "      all_keywords = self.remove_dup(all_keywords + self.recent_keywords)\n",
        "      print('len',len(df_questions_small))\n",
        "      self.update_config()\n",
        "      print('len',len(df_questions_small))\n",
        "      return self\n",
        "    elif self.nlp.cat_input_phrase(input) in [\"NEG\", \"NEG_S_EL\", \"NEG_ENC\"] and len(all_keywords) < self.MAX_KW:\n",
        "      return FrameDesenvolvimento2()\n",
        "    else:\n",
        "      return FrameCompreencao1()\n",
        "\n",
        "  def remove_dup(self, list_keywords):\n",
        "    keywords = [ s['word_id'] for s in list_keywords]\n",
        "    kw_atual_i = []\n",
        "    kw_final = []\n",
        "    for i in range(len(keywords)):\n",
        "      if keywords[i] not in kw_atual_i:\n",
        "        kw_atual_i.append(keywords[i])\n",
        "        kw_final.append(list_keywords[i])\n",
        "    return kw_final\n",
        "\n",
        "  def split_questions(self):\n",
        "    print(len(df_questions_small))\n",
        "    list_keywords = [s['word_id'] for s in self.recent_keywords]\n",
        "    print(list_keywords)\n",
        "    print(self.input_child)\n",
        "    self.questions_selected = df_questions_small[df_questions_small.apply(lambda row: row['KEY_WORDS (para usar nos ASSERTIONS)'] == list_keywords, axis=1)]\n",
        "    self.questions_deselected = df_questions_small[df_questions_small.apply(lambda row: row['KEY_WORDS (para usar nos ASSERTIONS)'] != list_keywords, axis=1)]\n",
        "    print(self.questions_selected)\n",
        "    print(self.questions_deselected)\n",
        "\n",
        "  def gen_option_list_messages(self):\n",
        "    self.options_list_massages = []\n",
        "    for _, row in self.questions_selected.iterrows():\n",
        "      question = row['PERGUNTA_FRASE_TEMPLATE']\n",
        "      for kw in self.recent_keywords:\n",
        "        question = question.replace(kw['word_id'], kw['word_used'])\n",
        "      self.options_list_massages.append(question)\n",
        "    print(self.recent_keywords)\n",
        "    print(self.questions_selected)\n",
        "    print(self.options_list_massages)\n",
        "    if len(self.options_list_massages) == 0:\n",
        "      self.options_list_massages.append(llm.create_question(self.input_child))\n",
        "\n",
        "  def update_config(self):\n",
        "    self.split_questions()\n",
        "    self.gen_option_list_messages()\n",
        "\n",
        "  def __init__(self, inicial_kw, input_child):\n",
        "    self.nlp = NLP()\n",
        "    self.queue_input_child = input_child\n",
        "    self.input_child = self.queue_input_child.pop(0)\n",
        "    self.options_list_massages = []\n",
        "    self.inicial_kw = inicial_kw\n",
        "    self.recent_keywords = self.inicial_kw['s'] + self.inicial_kw['v'] + self.inicial_kw['o']\n",
        "    global all_keywords\n",
        "    all_keywords = all_keywords + self.recent_keywords\n",
        "    self.update_config()\n",
        "    super().__init__(self.options_list_massages)\n",
        "\n",
        "class FrameDesenvolvimentoComplexo1(FrameEstateComp):\n",
        "  MAX_KW = 5 * PERC_KW_RATING\n",
        "\n",
        "  def next_frame(self, input):\n",
        "    global all_keywords\n",
        "    print(all_keywords)\n",
        "    if self.nlp.cat_input_phrase(input) in [\"POS\", \"NEG_C_EL\", \"LONG\", \"CURT\"] and len(all_keywords) < self.MAX_KW:\n",
        "      for question in self.options_list_massages:\n",
        "        for kw in self.recent_keywords:\n",
        "          question = question.replace(kw['word_used'], kw['word_id'])\n",
        "      self.questions_selected = self.questions_selected[self.questions_selected.apply(lambda row: row['PERGUNTA_FRASE_TEMPLATE'] in self.options_list_massages, axis=1)]\n",
        "      global df_questions_big\n",
        "      df_questions_big = pd.concat([self.questions_selected, self.questions_deselected])\n",
        "      print('len',len(df_questions_big))\n",
        "\n",
        "      self.queue_input_child.append(input)\n",
        "      temp_input = self.queue_input_child.pop(0)\n",
        "\n",
        "      self.inicial_kw = self.nlp.get_keywords(temp_input)\n",
        "      self.input_child = temp_input\n",
        "      print('len',len(df_questions_big))\n",
        "      self.options_list_massages = []\n",
        "      print('len',len(df_questions_big))\n",
        "      self.recent_keywords = self.inicial_kw['s'] + self.inicial_kw['v'] + self.inicial_kw['o']\n",
        "      print('len',len(df_questions_big))\n",
        "      all_keywords = self.remove_dup(all_keywords + self.recent_keywords)\n",
        "      print('len',len(df_questions_big))\n",
        "      self.update_config()\n",
        "      print('len',len(df_questions_big))\n",
        "      return self\n",
        "    elif self.nlp.cat_input_phrase(input) in [\"NEG\", \"NEG_S_EL\", \"NEG_ENC\"] and len(all_keywords) < self.MAX_KW:\n",
        "      return FrameDesenvolvimento2()\n",
        "    else:\n",
        "      return FrameCompreencao1()\n",
        "\n",
        "  def remove_dup(self, list_keywords):\n",
        "    keywords = [ s['word_id'] for s in list_keywords]\n",
        "    kw_atual_i = []\n",
        "    kw_final = []\n",
        "    for i in range(len(keywords)):\n",
        "      if keywords[i] not in kw_atual_i:\n",
        "        kw_atual_i.append(keywords[i])\n",
        "        kw_final.append(list_keywords[i])\n",
        "    return kw_final\n",
        "\n",
        "  def split_questions(self):\n",
        "    print(len(df_questions_big))\n",
        "    list_keywords = [s['word_id'] for s in self.recent_keywords]\n",
        "    print(list_keywords)\n",
        "    print(self.input_child)\n",
        "    self.questions_selected = df_questions_big[df_questions_big.apply(lambda row: row['KEY_WORDS (para usar nos ASSERTIONS)'] == list_keywords, axis=1)]\n",
        "    self.questions_deselected = df_questions_big[df_questions_big.apply(lambda row: row['KEY_WORDS (para usar nos ASSERTIONS)'] != list_keywords, axis=1)]\n",
        "    print(self.questions_selected)\n",
        "    print(self.questions_deselected)\n",
        "\n",
        "  def gen_option_list_messages(self):\n",
        "    self.options_list_massages = []\n",
        "    for _, row in self.questions_selected.iterrows():\n",
        "      question = row['PERGUNTA_FRASE_TEMPLATE']\n",
        "      for kw in self.recent_keywords:\n",
        "        question = question.replace(kw['word_id'], kw['word_used'])\n",
        "      self.options_list_massages.append(question)\n",
        "    if len(self.options_list_massages) == 0:\n",
        "      self.options_list_massages.append(llm.create_question(self.input_child))\n",
        "\n",
        "  def update_config(self):\n",
        "    self.split_questions()\n",
        "    self.gen_option_list_messages()\n",
        "\n",
        "  def __init__(self, inicial_kw, input_child):\n",
        "    self.nlp = NLP()\n",
        "    self.queue_input_child = input_child\n",
        "    self.input_child = self.queue_input_child.pop(0)\n",
        "    self.options_list_massages = []\n",
        "    self.inicial_kw = inicial_kw\n",
        "    self.recent_keywords = self.inicial_kw['s'] + self.inicial_kw['v'] + self.inicial_kw['o']\n",
        "    global all_keywords\n",
        "    all_keywords = all_keywords + self.recent_keywords\n",
        "    self.update_config()\n",
        "    super().__init__(self.options_list_massages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mDIOrB8TGSC"
      },
      "source": [
        "Habilidades LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQRdeJKKTFij"
      },
      "outputs": [],
      "source": [
        "class llmSkills:\n",
        "\n",
        "  def __init__(self):\n",
        "    model_repo = \"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\"\n",
        "    model_file = \"Meta-Llama-3.1-8B-Instruct-IQ3_M.gguf\"\n",
        "    self.llm = Llama.from_pretrained(repo_id = model_repo, filename = model_file, verbose = False, n_ctx = 2048, n_gpu_layers = -1)\n",
        "\n",
        "  def correct_grammar(self, input):\n",
        "    prompt = f\"\"\"\n",
        "    Por favor, corrija a gramática, a ortografia e a concordância da frase dada.\n",
        "\n",
        "    Frase dada:Olá Manuela, bem vindo! Nesta sessão 1 você vai ver um DESENHO 1.\n",
        "    Frase corrigida:Olá Manuela, bem vinda! Nesta sessão 1 você vai ver o desenho 1.\n",
        "    Frase dada:{input}\n",
        "    Frase corrigida:\"\"\"\n",
        "\n",
        "    outputs = self.llm(prompt, max_tokens = 500, stop = ['\\n','Frase dada:','Frase corrigida:'], temperature = 0.0, echo = False)\n",
        "    return outputs['choices'][0]['text']\n",
        "\n",
        "  def create_question(self, input):\n",
        "    prompt = f\"\"\"\n",
        "    Por favor, aja como um psicólogo infantil e elabore uma pergunta para criança sobre a imagem que ela esta observando. A pergunta para criança deve somente repetir a frase da criança e apenas acrecentar ao final um dos componente de pergunta. Não altere esta ordem e não acrescente informações adicionais a pergunta da criança.\n",
        "\n",
        "    Componente de pergunta: [como?, por que?, de que?, quais?, quantos?, que mais?, que?, onde?, mais o que?, 'e o que mais']\n",
        "    Frase da criança:{input}\n",
        "    Pergunta para criança:\"\"\"\n",
        "\n",
        "    outputs = self.llm(prompt, stop = ['\\n','Frase da criança:','Pergunta:'], temperature=0.0, echo = False)\n",
        "    return outputs['choices'][0]['text']\n",
        "\n",
        "  def categorize_phrase(self, input):\n",
        "    prompt = f\"\"\"\n",
        "    Por favor, classifique a frase dada em frase de encerramento, frase negativa, frase negativa com elementos ou frase positiva com elementos.\n",
        "\n",
        "    Frase dada:Já basta\n",
        "    Classificação:frase de encerramento\n",
        "    Frase dada:Não quero\n",
        "    Classificação:frase negativa\n",
        "    Frase dada:Odiei\n",
        "    Classificação:frase negativa\n",
        "    Frase dada:Não gosto do menino\n",
        "    Classificação:frase negativa com elementos\n",
        "    Frase dada:Tem uma criança brincando\n",
        "    Classificação:frase positiva com elementos\n",
        "    Frase dada:{input}\n",
        "    Classificação:\"\"\"\n",
        "\n",
        "    outputs = self.llm(prompt, stop = ['\\n','Frase dada:','Frase corrigida:'], temperature=0.0, echo = False)\n",
        "    return outputs['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzfkFeanBwrY"
      },
      "outputs": [],
      "source": [
        "class NLP:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.nlp = spacy.load(\"pt_core_news_sm\")\n",
        "    df_keywords = pd.read_excel(KEYWORD_FILEPATH)\n",
        "    self.sub_key = []\n",
        "    self.veb_key = []\n",
        "    self.adj_key = []\n",
        "    for kw in df_keywords['SUBSTANTIVOS']:\n",
        "      temp_list = kw.replace(':',',')\n",
        "      temp_list = temp_list.split(', ')\n",
        "      self.sub_key.append({\"id_kw\": temp_list[0], \"kw_list\": temp_list})\n",
        "    for kw in df_keywords['VERBOS']:\n",
        "      if isinstance(kw, float):\n",
        "        break\n",
        "      temp_list = kw.replace(':',',')\n",
        "      temp_list = temp_list.split(', ')\n",
        "      self.veb_key.append({\"id_kw\": temp_list[0], \"kw_list\": temp_list})\n",
        "    for kw in df_keywords['ADJETIVOS']:\n",
        "      if isinstance(kw, float):\n",
        "        break\n",
        "      temp_list = kw.replace(':',',')\n",
        "      temp_list = temp_list.split(', ')\n",
        "      self.adj_key.append({\"id_kw\": temp_list[0], \"kw_list\": temp_list})\n",
        "\n",
        "  def count_tokens(self, input):\n",
        "    doc = self.nlp(input)\n",
        "    return len(doc)\n",
        "\n",
        "  def cat_input_phrase(self, input):\n",
        "    input = input.lower().strip(' .!?')\n",
        "    if input == \"não\":\n",
        "      return \"NEG\"\n",
        "    elif input == \"sim\":\n",
        "      return \"POS\"\n",
        "    elif llm.categorize_phrase(input) == \"frase negativa\":\n",
        "      return \"NEG_S_EL\"\n",
        "    elif llm.categorize_phrase(input) == \"frase de encerramento\":\n",
        "      return \"NEG_ENC\"\n",
        "    elif llm.categorize_phrase(input) == \"frase negativa com elementos\":\n",
        "      return \"NEG_C_EL\"\n",
        "    else:\n",
        "      test = input.split('.')\n",
        "      if len(test) > 1:\n",
        "        return \"LONG\"\n",
        "      else:\n",
        "        return \"CURT\"\n",
        "\n",
        "  def get_keywords(self, input):\n",
        "    doc = self.nlp(input)\n",
        "    OBJECT_DEPS = {\"dobj\", \"dative\", \"attr\", \"oprd\", \"obj\", \"amod\", \"ROOT\", \"xcomp\", \"conj\", \"obl\"}\n",
        "    SUBJECT_DEPS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"agent\", \"expl\"}\n",
        "    s = []\n",
        "    v = []\n",
        "    o = []\n",
        "    id_key_word = None\n",
        "    finder = False\n",
        "    for token in doc:\n",
        "      print(token.text, token.dep_, token.pos_)\n",
        "      if (token.pos_ == \"NOUN\" or token.pos_ == \"PRON\") and token.dep_ in SUBJECT_DEPS:\n",
        "        for kws in self.sub_key:\n",
        "          if finder:\n",
        "            break\n",
        "          for kw in kws[\"kw_list\"]:\n",
        "            if finder:\n",
        "              break\n",
        "            if self.nlp(kw.lower())[0].lemma_ == self.nlp(token.text.lower())[0].lemma_:\n",
        "              s.append({\"word_used\": token.text,\"word_id\": kws['id_kw']})\n",
        "              finder = True\n",
        "        if token.pos_ == \"NOUN\" and not finder:\n",
        "          s.append({\"word_used\": token.text,\"word_id\": self.nlp(token.text.lower())[0].lemma_})\n",
        "      elif (token.pos_ == \"NOUN\" or token.pos_ == \"PRON\") and token.dep_ in OBJECT_DEPS:\n",
        "        for kws in self.sub_key:\n",
        "          if finder:\n",
        "            break\n",
        "          for kw in kws[\"kw_list\"]:\n",
        "            if finder:\n",
        "              break\n",
        "            if self.nlp(kw.lower())[0].lemma_ == self.nlp(token.text.lower())[0].lemma_:\n",
        "              o.append({\"word_used\": token.text,\"word_id\": kws['id_kw']})\n",
        "              finder = True\n",
        "        if token.pos_ == \"NOUN\" and not finder:\n",
        "          o.append({\"word_used\": token.text,\"word_id\": self.nlp(token.text.lower())[0].lemma_})\n",
        "      elif token.pos_ == \"VERB\":\n",
        "        for kws in self.veb_key:\n",
        "          if finder:\n",
        "            break\n",
        "          for kw in kws[\"kw_list\"]:\n",
        "            if finder:\n",
        "              break\n",
        "            if self.nlp(kw.lower())[0].lemma_ == self.nlp(token.text.lower())[0].lemma_:\n",
        "              v.append({\"word_used\": token.text,\"word_id\": kws['id_kw']})\n",
        "              finder = True\n",
        "      elif token.pos_ == \"ADJ\" and token.dep_ in OBJECT_DEPS:\n",
        "        for kws in self.adj_key:\n",
        "          if finder:\n",
        "            break\n",
        "          for kw in kws[\"kw_list\"]:\n",
        "            if finder:\n",
        "              break\n",
        "            if self.nlp(kw.lower())[0].lemma_ == self.nlp(token.text.lower())[0].lemma_:\n",
        "              o.append({\"word_used\": token.text, \"word_id\": kws['id_kw']})\n",
        "              finder = True\n",
        "\n",
        "      finder = False\n",
        "\n",
        "    return {\"s\": s, \"v\": v, \"o\": o}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31wfD84IJEbC"
      },
      "source": [
        "Controller do Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxyWDViIv5BP"
      },
      "outputs": [],
      "source": [
        "class ChatController:\n",
        "  def __init__(self):\n",
        "    self.frame_state = FrameSaudacao()\n",
        "    self.messages = [{\"role\":\"assistant\", \"content\":self.frame_state.randomOutput()}]\n",
        "\n",
        "  def get_messages(self):\n",
        "    return self.messages\n",
        "\n",
        "  def set_message(self, message):\n",
        "    if self.frame_state == None:\n",
        "      return\n",
        "    else:\n",
        "      message_content = message[\"content\"]\n",
        "      self.messages.append({\"role\":\"user\", \"content\":message_content})\n",
        "      self.frame_state = self.frame_state.next_frame(message_content)\n",
        "      if self.frame_state != None:\n",
        "        self.messages.append({\"role\":\"assistant\", \"content\":self.frame_state.randomOutput()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "099mEX1OJB1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7d2887-6b1c-4bb2-8e83-9ba2730aefac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá JOÃO, estou feliz de estar com você aqui. Vamos começar a SESSÃO 1.', 'Olá JOÃO, que bom que você veio. Vamos gravar a SESSÃO 1.', 'Olá JOÃO, bem vindo! Nesta SESSÃO 1 você vai ver um DESENHO 1.', 'Oi JOÃO, bem vindo, vamos começar a SESSÃO 1, com um DESENHO 1.', 'Oi JOÃO, vamos começar a SESSÃO 1,seja bem vindo. Na tela aparecem quatro DESENHO 1.', 'Oba JOÃO, que bom ter você aqui! Vamos começar a SESSÃO 1!']\n"
          ]
        }
      ],
      "source": [
        "llm = llmSkills()\n",
        "controller = ChatController()\n",
        "df_questions_small = pd.read_excel(SMALL_QUESTION_FILEPATH)\n",
        "df_questions_small['KEY_WORDS (para usar nos ASSERTIONS)'] = df_questions_small.apply(lambda row: row['KEY_WORDS (para usar nos ASSERTIONS)'][1:-1].split(', '), axis=1)\n",
        "df_questions_big = pd.read_excel(BIG_QUESTION_FILEPATH)\n",
        "df_questions_big['KEY_WORDS (para usar nos ASSERTIONS)'] = df_questions_big.apply(lambda row: row['KEY_WORDS (para usar nos ASSERTIONS)'][1:-1].split(', '), axis=1)\n",
        "all_keywords = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJc64ANhJVr4"
      },
      "source": [
        "Endpoint do servidor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFmw-vszje03"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def add_message(message):\n",
        "  controller.set_message(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWdnJP5Mju36"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def get_messages():\n",
        "  return controller.get_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mYUNoOxBx_Q"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def get_name_child():\n",
        "  return NOME_CRIANCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhg_4WvYkpSm",
        "outputId": "3d40e63b-0633-4e8d-c9dc-eb4152981c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nesta tela tem um DESENHO 1 que você vai olhar para contar uma história. Mas fique tranquilo, neste DESENHO 1 não tem, certo nem errado, é você que vai contar como quiser.', 'Nesta imagem na tela tem um DESENHO 1, você vai contar o que acontece, não tem certo nem errado, vai ser uma história criada por você.', 'Você está vendo na tela um DESENHO 1. Esse DESENHO 1 não tem certo, nem errado, é você quem vai contar como quiser a história. Também não tem resposta bonita e nem feia. É a sua resposta e por isso tem a sua importância!', 'Você vai contar sua própria história sobre esse DESENHO 1, sem ter certo e nem errado, combinado? Fique à vontade.', 'Para esse DESENHO 1, não tem certo nem errado, é você que vai contar uma história como quiser, conta pra mim.', 'Na tela está aparecendo um DESENHO 1. Pode me contar o que acontece na história? Pode contar como quiser, não tem certo nem errado, é você que vai criar uma história! Também não se preocupe com o tempo. Leve o tempo que você precisar para dar a sua resposta.']\n",
            "['Vamos lá, pode contar JOÃO sua historinha para mim?', 'Vamos começar, JOÃO?', 'Podemos começar, JOÃO?', 'Está pronto para começar, JOÃO?', 'Está pronto para iniciar, JOÃO?', 'JOÃO, podemos iniciar?', 'JOÃO, vamos iniciar?']\n",
            "['JOÃO Continuo aqui. Pode me falar o que você vê na imagem?', 'Vamos começar, JOÃO! Estou aqui para quando você quiser começar. O que você vê nos quadrinhos?', 'Continuo aguardando! Conte-me o que você está vendo na historinha.', 'Podemos começar assim que você quiser, me conte sua historinha JOÃO.', 'JOÃO, podemos iniciar: me conte qualquer historinha sobre essa imagem.', 'JOÃO, vamos iniciar. Estou aguardando você contar uma historinha sobre essa imagem.', 'JOÃO, me fale o que você vê na imagem.', 'Podemos começar assim que você quiser, me conte sua historinha JOÃO.']\n",
            "['JOÃO Continuo aqui, pode me falar o que você vê na imagem?', 'Vamos começar, JOÃO, estou aqui para quando você quiser começar. O que você vê nos quadrinhos?', 'Podemos começar assim que você quiser, me conte a historinha JOÃO?', 'JOÃO, podemos iniciar: me conte qualquer historinha sobre essa imagem.', 'JOÃO, vamos iniciar. Estou aguardando você contar uma historinha sobre essa imagem.']\n",
            "tem ROOT VERB\n",
            "um det DET\n",
            "cão obj NOUN\n",
            "21\n",
            "['cachorro']\n",
            "tem um cão\n",
            "Empty DataFrame\n",
            "Columns: [ID, PERGUNTA_FRASE, KEY_WORDS (para usar nos ASSERTIONS), PADRAO_SVO (USADO NA BUSCA)]\n",
            "Index: []\n",
            "    ID                                     PERGUNTA_FRASE  \\\n",
            "0    1  Ah, que legal! Detalhe mais sobre o que aconte...   \n",
            "1    2  <Eles> <conversavam> sobre o quê para <subirem...   \n",
            "2    3  Gostei muito dessa história que você contou! V...   \n",
            "3    4  Gostaria de entender por que <eles> <ficaram> ...   \n",
            "4    5  Você acha que o <cachorro> quer <morder> <eles...   \n",
            "5    6             O <cachorro> <está> <raivoso> por quê?   \n",
            "6    7  Que legal essa história tem um final feliz, me...   \n",
            "7    8  Por que você acha que <eles> <estão> <sorrindo...   \n",
            "8    9  Muito boa sua história! Então me explica melho...   \n",
            "9   10  Muito boa sua história! Então me explica melho...   \n",
            "10  11     Pode repetir como <eles> conseguiram <descer>?   \n",
            "11  12  Ah! Então me conte novamente como <eles> <desc...   \n",
            "12  13  Então, me conta mais sobre por que o <osso> <a...   \n",
            "13  14  Por que tem uma <cerca> nessa história? Pode e...   \n",
            "14  15  Pode explicar aquele momento que <eles>  <fica...   \n",
            "15  16  Por que o <cachorro>  <ficou>  <raivoso> e dep...   \n",
            "16  17  Pode explicar como <elas> conseguiram <descer>...   \n",
            "17  18  Conte para mim como as <crianças> conseguiram ...   \n",
            "18  19  Pode explicar com mais detalhes como <eles>  <...   \n",
            "19  20  Você percebeu que  <eles>  <estavam>  <sentado...   \n",
            "20  21  Como <eles> fizeram para conseguir <comer> as ...   \n",
            "\n",
            "               KEY_WORDS (para usar nos ASSERTIONS)  \\\n",
            "0                           [amigos, subir, árvore]   \n",
            "1                  [eles, conversar, subir, árvore]   \n",
            "2                            [eles, ficar, felizes]   \n",
            "3                               [eles, ficar, medo]   \n",
            "4                           [cachorro, moder, eles]   \n",
            "5                        [cachorro, estar, raivoso]   \n",
            "6               [eles, ficar, tranquilos, cachorro]   \n",
            "7                             [eles, estar, sorrir]   \n",
            "8                  [eles, fazer, cachorro, raivoso]   \n",
            "9                [eles, fazer, cachorro, tranquilo]   \n",
            "10                                   [eles, descer]   \n",
            "11  [eles, descer, estar, medo, sentado, tranquilo]   \n",
            "12                       [osso, aparecer, história]   \n",
            "13                                          [cerca]   \n",
            "14                        [eles, ficar, assustados]   \n",
            "15            [cachorro, ficar, raivoso, tranquilo]   \n",
            "16                           [eles, descer, arvore]   \n",
            "17                             [crianças, divertir]   \n",
            "18                        [eles, ficar, tranquilos]   \n",
            "19              [eles, estar, sentados, tranquilos]   \n",
            "20                             [eles, comer, maçãs]   \n",
            "\n",
            "   PADRAO_SVO (USADO NA BUSCA)  \n",
            "0                       2S1V1O  \n",
            "1                       2S2V1O  \n",
            "2                       2S1V2O  \n",
            "3                       2S1V1O  \n",
            "4                       1S1V2O  \n",
            "5                       1S1V1O  \n",
            "6                       2S1V2O  \n",
            "7                       2S1V1O  \n",
            "8                       2S1V2O  \n",
            "9                       2S1V2O  \n",
            "10                        2S1V  \n",
            "11                     2S2V2O   \n",
            "12                      1S1V1O  \n",
            "13                          1S  \n",
            "14                      2S1V2O  \n",
            "15                      1S1V2O  \n",
            "16                      2S1V1O  \n",
            "17                        2S1V  \n",
            "18                      2S1V2O  \n",
            "19                      2S1V2O  \n",
            "20                      2S1V2O  \n",
            "[' tem um cão que mais?']\n",
            "[{'word_used': 'cão', 'word_id': 'cachorro'}]\n",
            "['Certo, e o que mais?', 'O que mais podemos dizer dos outros quadrinhos na sua história?', 'Entendi. E o que mais?', 'Você pode me contar também dos outros quadrinhos?', 'Vamos continuar a história, passando para outros quadrinhos?', 'Que interessante! Agora conte também um pouco mais o que acontece nos outros quadrinhos.', 'E o que mais acontece em sua história?', 'Que interessante! Conte mais o que aconteceu?', 'E o que mais?', 'E aí? Conte mais.', 'Então, o que mais aconteceu?']\n",
            "['Maravilha! Pode repetir e contar de novo de uma vez só para encerrar?', 'Ótimo! Gostei, poderia repetir a história toda, apenas para finalizar?', 'Há algo mais que você queira contar sobre esse DESENHO 1, JOÃO?', 'Mais alguma coisa a dizer sobre esse DESENHO 1?', 'Pode me dizer mais alguma coisas a respeito desse DESENHO 1?', 'JOÃO, gostei muito de sua história. Pode contar de novo para eu gravar melhor?', 'Excelente história, JOÃO! Pode repetir toda a historinha de uma vez para encerrar a sessão?']\n"
          ]
        }
      ],
      "source": [
        "anvil.server.wait_forever()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}